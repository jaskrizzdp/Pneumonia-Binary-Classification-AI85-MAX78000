2025-10-29 03:37:49,668 - Log file for this run: D:\KRIZZ\COE187\ai8x-training\logs\2025.10.29-033749\2025.10.29-033749.log
2025-10-29 03:37:49,668 - Configuring device: MAX78000, simulate=False.
2025-10-29 03:37:49,668 - No CUDA, ROCm, or MPS hardware acceleration, training will be slow
2025-10-29 03:37:49,668 - 
2025-10-29 03:37:49,668 - --------------------------------------------------------
2025-10-29 03:37:49,668 - Logging to TensorBoard - remember to execute the server:
2025-10-29 03:37:49,668 - > tensorboard --logdir='./logs'
2025-10-29 03:37:49,668 - 
2025-10-29 03:37:50,119 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2025-10-29 03:37:50,119 - Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'decoupled_weight_decay': False}
2025-10-29 03:37:50,447 - D:\KRIZZ\COE187\ai8x-training\datasets\chest_xray.py:51: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise
  album.GaussNoise(var_limit=(1.0, 20.0), p=0.25),

2025-10-29 03:37:50,447 - D:\KRIZZ\COE187\venv\Lib\site-packages\albumentations\core\validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.
  original_init(self, **validated_kwargs)

2025-10-29 03:37:50,514 - Reading compression schedule from: policies/schedule-pneumonia.yaml
2025-10-29 03:37:50,519 - torch.compile() not available, using "eager" mode
2025-10-29 03:37:50,519 - Dataset sizes:
	training=4695
	validation=521
	test=624
2025-10-29 03:37:50,519 - 

2025-10-29 03:37:50,520 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 03:39:30,953 - Epoch: [0][   10/   19]    Overall Loss 0.597757    Objective Loss 0.597757                                        LR 0.001000    Time 10.043226    
2025-10-29 03:40:06,732 - Epoch: [0][   19/   19]    Overall Loss 0.538316    Objective Loss 0.538316    Top1 81.924198    LR 0.001000    Time 7.164823    
2025-10-29 03:40:07,989 - --- validate (epoch=0)-----------
2025-10-29 03:40:07,989 - 521 samples (256 per mini-batch)
2025-10-29 03:40:56,195 - Epoch: [0][    3/    3]    Loss 0.494686    Top1 76.391555    
2025-10-29 03:40:57,718 - ==> Top1: 76.392    Loss: 0.495

2025-10-29 03:40:57,718 - ==> Confusion:
[[102  35]
 [ 88 296]]

2025-10-29 03:40:57,812 - ==> Best [Top1: 76.392   Params: 57776 on epoch: 0]
2025-10-29 03:40:57,812 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 03:40:57,835 - 

2025-10-29 03:40:57,835 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 03:42:44,030 - Epoch: [1][   10/   19]    Overall Loss 0.416168    Objective Loss 0.416168                                        LR 0.001000    Time 10.619406    
2025-10-29 03:43:17,679 - Epoch: [1][   19/   19]    Overall Loss 0.396844    Objective Loss 0.396844    Top1 83.673469    LR 0.001000    Time 7.355052    
2025-10-29 03:43:19,030 - --- validate (epoch=1)-----------
2025-10-29 03:43:19,031 - 521 samples (256 per mini-batch)
2025-10-29 03:44:01,238 - Epoch: [1][    3/    3]    Loss 0.299280    Top1 83.685221    
2025-10-29 03:44:02,574 - ==> Top1: 83.685    Loss: 0.299

2025-10-29 03:44:02,575 - ==> Confusion:
[[ 77  60]
 [ 25 359]]

2025-10-29 03:44:02,652 - ==> Best [Top1: 83.685   Params: 57776 on epoch: 1]
2025-10-29 03:44:02,652 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 03:44:02,662 - 

2025-10-29 03:44:02,663 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 03:45:41,291 - Epoch: [2][   10/   19]    Overall Loss 0.313277    Objective Loss 0.313277                                        LR 0.001000    Time 9.862779    
2025-10-29 03:46:15,034 - Epoch: [2][   19/   19]    Overall Loss 0.304882    Objective Loss 0.304882    Top1 90.087464    LR 0.001000    Time 6.961992    
2025-10-29 03:46:16,392 - --- validate (epoch=2)-----------
2025-10-29 03:46:16,393 - 521 samples (256 per mini-batch)
2025-10-29 03:46:58,590 - Epoch: [2][    3/    3]    Loss 0.315138    Top1 87.140115    
2025-10-29 03:46:59,895 - ==> Top1: 87.140    Loss: 0.315

2025-10-29 03:46:59,895 - ==> Confusion:
[[101  36]
 [ 31 353]]

2025-10-29 03:46:59,964 - ==> Best [Top1: 87.140   Params: 57776 on epoch: 2]
2025-10-29 03:46:59,965 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 03:46:59,991 - 

2025-10-29 03:46:59,991 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 03:48:38,632 - Epoch: [3][   10/   19]    Overall Loss 0.286999    Objective Loss 0.286999                                        LR 0.001000    Time 9.863843    
2025-10-29 03:49:13,807 - Epoch: [3][   19/   19]    Overall Loss 0.283462    Objective Loss 0.283462    Top1 88.046647    LR 0.001000    Time 7.039834    
2025-10-29 03:49:15,110 - --- validate (epoch=3)-----------
2025-10-29 03:49:15,110 - 521 samples (256 per mini-batch)
2025-10-29 03:49:56,962 - Epoch: [3][    3/    3]    Loss 0.357110    Top1 90.211132    
2025-10-29 03:49:58,301 - ==> Top1: 90.211    Loss: 0.357

2025-10-29 03:49:58,301 - ==> Confusion:
[[103  34]
 [ 17 367]]

2025-10-29 03:49:58,375 - ==> Best [Top1: 90.211   Params: 57776 on epoch: 3]
2025-10-29 03:49:58,376 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 03:49:58,389 - 

2025-10-29 03:49:58,389 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 03:51:35,934 - Epoch: [4][   10/   19]    Overall Loss 0.270830    Objective Loss 0.270830                                        LR 0.001000    Time 9.754306    
2025-10-29 03:52:09,859 - Epoch: [4][   19/   19]    Overall Loss 0.275537    Objective Loss 0.275537    Top1 88.921283    LR 0.001000    Time 6.914182    
2025-10-29 03:52:11,227 - --- validate (epoch=4)-----------
2025-10-29 03:52:11,228 - 521 samples (256 per mini-batch)
2025-10-29 03:52:52,826 - Epoch: [4][    3/    3]    Loss 0.280427    Top1 90.786948    
2025-10-29 03:52:54,152 - ==> Top1: 90.787    Loss: 0.280

2025-10-29 03:52:54,153 - ==> Confusion:
[[120  17]
 [ 31 353]]

2025-10-29 03:52:54,220 - ==> Best [Top1: 90.787   Params: 57776 on epoch: 4]
2025-10-29 03:52:54,221 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 03:52:54,245 - 

2025-10-29 03:52:54,246 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 03:54:28,004 - Epoch: [5][   10/   19]    Overall Loss 0.234052    Objective Loss 0.234052                                        LR 0.001000    Time 9.375802    
2025-10-29 03:55:03,713 - Epoch: [5][   19/   19]    Overall Loss 0.243943    Objective Loss 0.243943    Top1 90.962099    LR 0.001000    Time 6.809711    
2025-10-29 03:55:05,009 - --- validate (epoch=5)-----------
2025-10-29 03:55:05,010 - 521 samples (256 per mini-batch)
2025-10-29 03:55:46,714 - Epoch: [5][    3/    3]    Loss 0.295646    Top1 91.554702    
2025-10-29 03:55:48,045 - ==> Top1: 91.555    Loss: 0.296

2025-10-29 03:55:48,046 - ==> Confusion:
[[105  32]
 [ 12 372]]

2025-10-29 03:55:48,110 - ==> Best [Top1: 91.555   Params: 57776 on epoch: 5]
2025-10-29 03:55:48,110 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 03:55:48,131 - 

2025-10-29 03:55:48,132 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 03:57:22,360 - Epoch: [6][   10/   19]    Overall Loss 0.235457    Objective Loss 0.235457                                        LR 0.001000    Time 9.422774    
2025-10-29 03:57:57,271 - Epoch: [6][   19/   19]    Overall Loss 0.226797    Objective Loss 0.226797    Top1 93.294461    LR 0.001000    Time 6.794153    
2025-10-29 03:57:58,588 - --- validate (epoch=6)-----------
2025-10-29 03:57:58,588 - 521 samples (256 per mini-batch)
2025-10-29 03:58:40,310 - Epoch: [6][    3/    3]    Loss 0.175533    Top1 91.170825    
2025-10-29 03:58:41,632 - ==> Top1: 91.171    Loss: 0.176

2025-10-29 03:58:41,633 - ==> Confusion:
[[125  12]
 [ 34 350]]

2025-10-29 03:58:41,697 - ==> Best [Top1: 91.555   Params: 57776 on epoch: 5]
2025-10-29 03:58:41,697 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 03:58:41,705 - 

2025-10-29 03:58:41,706 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 04:00:15,818 - Epoch: [7][   10/   19]    Overall Loss 0.223704    Objective Loss 0.223704                                        LR 0.001000    Time 9.410988    
2025-10-29 04:00:52,108 - Epoch: [7][   19/   19]    Overall Loss 0.203264    Objective Loss 0.203264    Top1 91.836735    LR 0.001000    Time 6.858554    
2025-10-29 04:00:53,516 - --- validate (epoch=7)-----------
2025-10-29 04:00:53,516 - 521 samples (256 per mini-batch)
2025-10-29 04:01:35,379 - Epoch: [7][    3/    3]    Loss 0.251615    Top1 91.362764    
2025-10-29 04:01:36,726 - ==> Top1: 91.363    Loss: 0.252

2025-10-29 04:01:36,726 - ==> Confusion:
[[128   9]
 [ 36 348]]

2025-10-29 04:01:36,794 - ==> Best [Top1: 91.555   Params: 57776 on epoch: 5]
2025-10-29 04:01:36,794 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 04:01:36,801 - 

2025-10-29 04:01:36,801 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 04:03:13,203 - Epoch: [8][   10/   19]    Overall Loss 0.231752    Objective Loss 0.231752                                        LR 0.001000    Time 9.640109    
2025-10-29 04:03:47,030 - Epoch: [8][   19/   19]    Overall Loss 0.227452    Objective Loss 0.227452    Top1 90.087464    LR 0.001000    Time 6.851540    
2025-10-29 04:03:48,358 - --- validate (epoch=8)-----------
2025-10-29 04:03:48,358 - 521 samples (256 per mini-batch)
2025-10-29 04:04:30,402 - Epoch: [8][    3/    3]    Loss 0.131300    Top1 93.857965    
2025-10-29 04:04:31,739 - ==> Top1: 93.858    Loss: 0.131

2025-10-29 04:04:31,739 - ==> Confusion:
[[113  24]
 [  8 376]]

2025-10-29 04:04:31,811 - ==> Best [Top1: 93.858   Params: 57776 on epoch: 8]
2025-10-29 04:04:31,812 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 04:04:31,823 - 

2025-10-29 04:04:31,824 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 04:06:04,468 - Epoch: [9][   10/   19]    Overall Loss 0.205809    Objective Loss 0.205809                                        LR 0.001000    Time 9.264240    
2025-10-29 04:06:40,284 - Epoch: [9][   19/   19]    Overall Loss 0.214754    Objective Loss 0.214754    Top1 92.128280    LR 0.001000    Time 6.758298    
2025-10-29 04:06:41,600 - --- validate (epoch=9)-----------
2025-10-29 04:06:41,600 - 521 samples (256 per mini-batch)
2025-10-29 04:07:23,790 - Epoch: [9][    3/    3]    Loss 0.165567    Top1 93.474088    
2025-10-29 04:07:25,114 - ==> Top1: 93.474    Loss: 0.166

2025-10-29 04:07:25,114 - ==> Confusion:
[[110  27]
 [  7 377]]

2025-10-29 04:07:25,181 - ==> Best [Top1: 93.858   Params: 57776 on epoch: 8]
2025-10-29 04:07:25,181 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 04:07:25,188 - 

2025-10-29 04:07:25,188 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 04:08:59,619 - Epoch: [10][   10/   19]    Overall Loss 0.197257    Objective Loss 0.197257                                        LR 0.001000    Time 9.442875    
2025-10-29 04:09:36,087 - Epoch: [10][   19/   19]    Overall Loss 0.197929    Objective Loss 0.197929    Top1 93.586006    LR 0.001000    Time 6.885391    
2025-10-29 04:09:37,423 - --- validate (epoch=10)-----------
2025-10-29 04:09:37,424 - 521 samples (256 per mini-batch)
2025-10-29 04:10:19,178 - Epoch: [10][    3/    3]    Loss 0.179569    Top1 93.857965    
2025-10-29 04:10:20,499 - ==> Top1: 93.858    Loss: 0.180

2025-10-29 04:10:20,499 - ==> Confusion:
[[125  12]
 [ 20 364]]

2025-10-29 04:10:20,562 - ==> Best [Top1: 93.858   Params: 57776 on epoch: 10]
2025-10-29 04:10:20,563 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 04:10:20,587 - 

2025-10-29 04:10:20,587 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 04:11:54,567 - Epoch: [11][   10/   19]    Overall Loss 0.190086    Objective Loss 0.190086                                        LR 0.001000    Time 9.397613    
2025-10-29 04:12:30,392 - Epoch: [11][   19/   19]    Overall Loss 0.181989    Objective Loss 0.181989    Top1 93.586006    LR 0.001000    Time 6.827737    
2025-10-29 04:12:31,710 - --- validate (epoch=11)-----------
2025-10-29 04:12:31,711 - 521 samples (256 per mini-batch)
2025-10-29 04:13:13,833 - Epoch: [11][    3/    3]    Loss 0.229450    Top1 94.049904    
2025-10-29 04:13:15,155 - ==> Top1: 94.050    Loss: 0.229

2025-10-29 04:13:15,156 - ==> Confusion:
[[114  23]
 [  8 376]]

2025-10-29 04:13:15,223 - ==> Best [Top1: 94.050   Params: 57776 on epoch: 11]
2025-10-29 04:13:15,223 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 04:13:15,243 - 

2025-10-29 04:13:15,244 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 04:14:50,960 - Epoch: [12][   10/   19]    Overall Loss 0.155872    Objective Loss 0.155872                                        LR 0.001000    Time 9.571433    
2025-10-29 04:15:24,832 - Epoch: [12][   19/   19]    Overall Loss 0.169592    Objective Loss 0.169592    Top1 92.128280    LR 0.001000    Time 6.817506    
2025-10-29 04:15:26,128 - --- validate (epoch=12)-----------
2025-10-29 04:15:26,128 - 521 samples (256 per mini-batch)
2025-10-29 04:16:07,768 - Epoch: [12][    3/    3]    Loss 0.146867    Top1 94.049904    
2025-10-29 04:16:09,115 - ==> Top1: 94.050    Loss: 0.147

2025-10-29 04:16:09,116 - ==> Confusion:
[[123  14]
 [ 17 367]]

2025-10-29 04:16:09,181 - ==> Best [Top1: 94.050   Params: 57776 on epoch: 12]
2025-10-29 04:16:09,182 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 04:16:09,200 - 

2025-10-29 04:16:09,200 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 04:17:43,526 - Epoch: [13][   10/   19]    Overall Loss 0.172077    Objective Loss 0.172077                                        LR 0.001000    Time 9.432584    
2025-10-29 04:18:17,937 - Epoch: [13][   19/   19]    Overall Loss 0.161271    Objective Loss 0.161271    Top1 94.169096    LR 0.001000    Time 6.772575    
2025-10-29 04:18:19,251 - --- validate (epoch=13)-----------
2025-10-29 04:18:19,251 - 521 samples (256 per mini-batch)
2025-10-29 04:19:01,055 - Epoch: [13][    3/    3]    Loss 0.135505    Top1 93.857965    
2025-10-29 04:19:02,371 - ==> Top1: 93.858    Loss: 0.136

2025-10-29 04:19:02,371 - ==> Confusion:
[[126  11]
 [ 21 363]]

2025-10-29 04:19:02,434 - ==> Best [Top1: 94.050   Params: 57776 on epoch: 12]
2025-10-29 04:19:02,435 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 04:19:02,443 - 

2025-10-29 04:19:02,443 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 04:20:38,579 - Epoch: [14][   10/   19]    Overall Loss 0.171061    Objective Loss 0.171061                                        LR 0.001000    Time 9.613584    
2025-10-29 04:21:12,541 - Epoch: [14][   19/   19]    Overall Loss 0.181059    Objective Loss 0.181059    Top1 95.918367    LR 0.001000    Time 6.843433    
2025-10-29 04:21:13,885 - --- validate (epoch=14)-----------
2025-10-29 04:21:13,885 - 521 samples (256 per mini-batch)
2025-10-29 04:21:56,114 - Epoch: [14][    3/    3]    Loss 0.164028    Top1 91.170825    
2025-10-29 04:21:57,414 - ==> Top1: 91.171    Loss: 0.164

2025-10-29 04:21:57,415 - ==> Confusion:
[[ 93  44]
 [  2 382]]

2025-10-29 04:21:57,479 - ==> Best [Top1: 94.050   Params: 57776 on epoch: 12]
2025-10-29 04:21:57,479 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 04:21:57,486 - 

2025-10-29 04:21:57,486 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 04:23:31,088 - Epoch: [15][   10/   19]    Overall Loss 0.169045    Objective Loss 0.169045                                        LR 0.001000    Time 9.359881    
2025-10-29 04:24:07,705 - Epoch: [15][   19/   19]    Overall Loss 0.160184    Objective Loss 0.160184    Top1 95.043732    LR 0.001000    Time 6.849075    
2025-10-29 04:24:09,036 - --- validate (epoch=15)-----------
2025-10-29 04:24:09,036 - 521 samples (256 per mini-batch)
2025-10-29 04:24:50,794 - Epoch: [15][    3/    3]    Loss 0.123819    Top1 94.241843    
2025-10-29 04:24:52,124 - ==> Top1: 94.242    Loss: 0.124

2025-10-29 04:24:52,124 - ==> Confusion:
[[129   8]
 [ 22 362]]

2025-10-29 04:24:52,187 - ==> Best [Top1: 94.242   Params: 57776 on epoch: 15]
2025-10-29 04:24:52,187 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 04:24:52,211 - 

2025-10-29 04:24:52,212 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 04:26:27,550 - Epoch: [16][   10/   19]    Overall Loss 0.150870    Objective Loss 0.150870                                        LR 0.001000    Time 9.533675    
2025-10-29 04:27:00,953 - Epoch: [16][   19/   19]    Overall Loss 0.145379    Objective Loss 0.145379    Top1 94.460641    LR 0.001000    Time 6.767134    
2025-10-29 04:27:02,255 - --- validate (epoch=16)-----------
2025-10-29 04:27:02,255 - 521 samples (256 per mini-batch)
2025-10-29 04:27:44,637 - Epoch: [16][    3/    3]    Loss 0.103232    Top1 95.201536    
2025-10-29 04:27:45,960 - ==> Top1: 95.202    Loss: 0.103

2025-10-29 04:27:45,961 - ==> Confusion:
[[120  17]
 [  8 376]]

2025-10-29 04:27:46,025 - ==> Best [Top1: 95.202   Params: 57776 on epoch: 16]
2025-10-29 04:27:46,026 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 04:27:46,040 - 

2025-10-29 04:27:46,041 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 04:29:18,936 - Epoch: [17][   10/   19]    Overall Loss 0.148127    Objective Loss 0.148127                                        LR 0.001000    Time 9.289459    
2025-10-29 04:29:53,630 - Epoch: [17][   19/   19]    Overall Loss 0.155746    Objective Loss 0.155746    Top1 93.002915    LR 0.001000    Time 6.711262    
2025-10-29 04:29:54,959 - --- validate (epoch=17)-----------
2025-10-29 04:29:54,960 - 521 samples (256 per mini-batch)
2025-10-29 04:30:36,676 - Epoch: [17][    3/    3]    Loss 0.141836    Top1 95.969290    
2025-10-29 04:30:37,995 - ==> Top1: 95.969    Loss: 0.142

2025-10-29 04:30:37,995 - ==> Confusion:
[[127  10]
 [ 11 373]]

2025-10-29 04:30:38,059 - ==> Best [Top1: 95.969   Params: 57776 on epoch: 17]
2025-10-29 04:30:38,059 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 04:30:38,075 - 

2025-10-29 04:30:38,075 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 04:32:11,581 - Epoch: [18][   10/   19]    Overall Loss 0.160430    Objective Loss 0.160430                                        LR 0.001000    Time 9.350496    
2025-10-29 04:32:46,795 - Epoch: [18][   19/   19]    Overall Loss 0.170846    Objective Loss 0.170846    Top1 95.043732    LR 0.001000    Time 6.772315    
2025-10-29 04:32:48,091 - --- validate (epoch=18)-----------
2025-10-29 04:32:48,092 - 521 samples (256 per mini-batch)
2025-10-29 04:33:30,103 - Epoch: [18][    3/    3]    Loss 0.167227    Top1 95.777351    
2025-10-29 04:33:31,446 - ==> Top1: 95.777    Loss: 0.167

2025-10-29 04:33:31,446 - ==> Confusion:
[[121  16]
 [  6 378]]

2025-10-29 04:33:31,508 - ==> Best [Top1: 95.969   Params: 57776 on epoch: 17]
2025-10-29 04:33:31,509 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 04:33:31,515 - 

2025-10-29 04:33:31,516 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 04:35:07,030 - Epoch: [19][   10/   19]    Overall Loss 0.154271    Objective Loss 0.154271                                        LR 0.001000    Time 9.551300    
2025-10-29 04:35:42,083 - Epoch: [19][   19/   19]    Overall Loss 0.143307    Objective Loss 0.143307    Top1 95.043732    LR 0.001000    Time 6.869266    
2025-10-29 04:35:43,389 - --- validate (epoch=19)-----------
2025-10-29 04:35:43,389 - 521 samples (256 per mini-batch)
2025-10-29 04:36:25,333 - Epoch: [19][    3/    3]    Loss 0.129118    Top1 95.393474    
2025-10-29 04:36:26,731 - ==> Top1: 95.393    Loss: 0.129

2025-10-29 04:36:26,732 - ==> Confusion:
[[120  17]
 [  7 377]]

2025-10-29 04:36:26,807 - ==> Best [Top1: 95.969   Params: 57776 on epoch: 17]
2025-10-29 04:36:26,808 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 04:36:26,817 - 

2025-10-29 04:36:26,817 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 04:38:00,671 - Epoch: [20][   10/   19]    Overall Loss 0.137709    Objective Loss 0.137709                                        LR 0.000500    Time 9.385361    
2025-10-29 04:38:36,345 - Epoch: [20][   19/   19]    Overall Loss 0.142922    Objective Loss 0.142922    Top1 95.626822    LR 0.000500    Time 6.813770    
2025-10-29 04:38:37,665 - --- validate (epoch=20)-----------
2025-10-29 04:38:37,666 - 521 samples (256 per mini-batch)
2025-10-29 04:39:19,584 - Epoch: [20][    3/    3]    Loss 0.111696    Top1 94.817658    
2025-10-29 04:39:20,982 - ==> Top1: 94.818    Loss: 0.112

2025-10-29 04:39:20,982 - ==> Confusion:
[[118  19]
 [  8 376]]

2025-10-29 04:39:21,057 - ==> Best [Top1: 95.969   Params: 57776 on epoch: 17]
2025-10-29 04:39:21,057 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 04:39:21,064 - 

2025-10-29 04:39:21,064 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 04:40:55,771 - Epoch: [21][   10/   19]    Overall Loss 0.145632    Objective Loss 0.145632                                        LR 0.000500    Time 9.470584    
2025-10-29 04:41:29,213 - Epoch: [21][   19/   19]    Overall Loss 0.132227    Objective Loss 0.132227    Top1 94.752187    LR 0.000500    Time 6.739886    
2025-10-29 04:41:30,555 - --- validate (epoch=21)-----------
2025-10-29 04:41:30,555 - 521 samples (256 per mini-batch)
2025-10-29 04:42:12,219 - Epoch: [21][    3/    3]    Loss 0.200372    Top1 95.585413    
2025-10-29 04:42:13,565 - ==> Top1: 95.585    Loss: 0.200

2025-10-29 04:42:13,565 - ==> Confusion:
[[122  15]
 [  8 376]]

2025-10-29 04:42:13,631 - ==> Best [Top1: 95.969   Params: 57776 on epoch: 17]
2025-10-29 04:42:13,631 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 04:42:13,638 - 

2025-10-29 04:42:13,638 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 04:43:46,988 - Epoch: [22][   10/   19]    Overall Loss 0.121496    Objective Loss 0.121496                                        LR 0.000500    Time 9.334968    
2025-10-29 04:44:23,850 - Epoch: [22][   19/   19]    Overall Loss 0.125762    Objective Loss 0.125762    Top1 94.752187    LR 0.000500    Time 6.848722    
2025-10-29 04:44:25,163 - --- validate (epoch=22)-----------
2025-10-29 04:44:25,163 - 521 samples (256 per mini-batch)
2025-10-29 04:45:06,930 - Epoch: [22][    3/    3]    Loss 0.109656    Top1 95.777351    
2025-10-29 04:45:08,279 - ==> Top1: 95.777    Loss: 0.110

2025-10-29 04:45:08,279 - ==> Confusion:
[[122  15]
 [  7 377]]

2025-10-29 04:45:08,349 - ==> Best [Top1: 95.969   Params: 57776 on epoch: 17]
2025-10-29 04:45:08,349 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 04:45:08,357 - 

2025-10-29 04:45:08,357 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 04:46:44,802 - Epoch: [23][   10/   19]    Overall Loss 0.125179    Objective Loss 0.125179                                        LR 0.000500    Time 9.644476    
2025-10-29 04:47:17,985 - Epoch: [23][   19/   19]    Overall Loss 0.138575    Objective Loss 0.138575    Top1 94.169096    LR 0.000500    Time 6.819859    
2025-10-29 04:47:19,297 - --- validate (epoch=23)-----------
2025-10-29 04:47:19,298 - 521 samples (256 per mini-batch)
2025-10-29 04:48:01,334 - Epoch: [23][    3/    3]    Loss 0.077948    Top1 96.353167    
2025-10-29 04:48:02,671 - ==> Top1: 96.353    Loss: 0.078

2025-10-29 04:48:02,672 - ==> Confusion:
[[127  10]
 [  9 375]]

2025-10-29 04:48:02,740 - ==> Best [Top1: 96.353   Params: 57776 on epoch: 23]
2025-10-29 04:48:02,741 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 04:48:02,762 - 

2025-10-29 04:48:02,763 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 04:49:39,674 - Epoch: [24][   10/   19]    Overall Loss 0.135484    Objective Loss 0.135484                                        LR 0.000500    Time 9.691111    
2025-10-29 04:50:14,785 - Epoch: [24][   19/   19]    Overall Loss 0.141811    Objective Loss 0.141811    Top1 92.711370    LR 0.000500    Time 6.945219    
2025-10-29 04:50:16,093 - --- validate (epoch=24)-----------
2025-10-29 04:50:16,093 - 521 samples (256 per mini-batch)
2025-10-29 04:50:58,728 - Epoch: [24][    3/    3]    Loss 0.154058    Top1 94.625720    
2025-10-29 04:51:00,075 - ==> Top1: 94.626    Loss: 0.154

2025-10-29 04:51:00,075 - ==> Confusion:
[[128   9]
 [ 19 365]]

2025-10-29 04:51:00,143 - ==> Best [Top1: 96.353   Params: 57776 on epoch: 23]
2025-10-29 04:51:00,144 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 04:51:00,151 - 

2025-10-29 04:51:00,152 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 04:52:35,179 - Epoch: [25][   10/   19]    Overall Loss 0.129722    Objective Loss 0.129722                                        LR 0.000500    Time 9.502596    
2025-10-29 04:53:09,723 - Epoch: [25][   19/   19]    Overall Loss 0.128699    Objective Loss 0.128699    Top1 94.752187    LR 0.000500    Time 6.815640    
2025-10-29 04:53:11,046 - --- validate (epoch=25)-----------
2025-10-29 04:53:11,047 - 521 samples (256 per mini-batch)
2025-10-29 04:53:53,382 - Epoch: [25][    3/    3]    Loss 0.083101    Top1 96.928983    
2025-10-29 04:53:54,712 - ==> Top1: 96.929    Loss: 0.083

2025-10-29 04:53:54,713 - ==> Confusion:
[[128   9]
 [  7 377]]

2025-10-29 04:53:54,785 - ==> Best [Top1: 96.929   Params: 57776 on epoch: 25]
2025-10-29 04:53:54,786 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 04:53:54,800 - 

2025-10-29 04:53:54,801 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 04:55:29,873 - Epoch: [26][   10/   19]    Overall Loss 0.115857    Objective Loss 0.115857                                        LR 0.000500    Time 9.507159    
2025-10-29 04:56:05,637 - Epoch: [26][   19/   19]    Overall Loss 0.125497    Objective Loss 0.125497    Top1 95.043732    LR 0.000500    Time 6.881825    
2025-10-29 04:56:06,954 - --- validate (epoch=26)-----------
2025-10-29 04:56:06,954 - 521 samples (256 per mini-batch)
2025-10-29 04:56:48,789 - Epoch: [26][    3/    3]    Loss 0.107356    Top1 95.585413    
2025-10-29 04:56:50,137 - ==> Top1: 95.585    Loss: 0.107

2025-10-29 04:56:50,137 - ==> Confusion:
[[120  17]
 [  6 378]]

2025-10-29 04:56:50,198 - ==> Best [Top1: 96.929   Params: 57776 on epoch: 25]
2025-10-29 04:56:50,198 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 04:56:50,206 - 

2025-10-29 04:56:50,206 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 04:58:26,353 - Epoch: [27][   10/   19]    Overall Loss 0.114677    Objective Loss 0.114677                                        LR 0.000500    Time 9.614628    
2025-10-29 04:58:58,481 - Epoch: [27][   19/   19]    Overall Loss 0.117251    Objective Loss 0.117251    Top1 95.918367    LR 0.000500    Time 6.748176    
2025-10-29 04:58:59,805 - --- validate (epoch=27)-----------
2025-10-29 04:58:59,806 - 521 samples (256 per mini-batch)
2025-10-29 04:59:42,041 - Epoch: [27][    3/    3]    Loss 0.110195    Top1 96.353167    
2025-10-29 04:59:43,366 - ==> Top1: 96.353    Loss: 0.110

2025-10-29 04:59:43,366 - ==> Confusion:
[[132   5]
 [ 14 370]]

2025-10-29 04:59:43,434 - ==> Best [Top1: 96.929   Params: 57776 on epoch: 25]
2025-10-29 04:59:43,434 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 04:59:43,440 - 

2025-10-29 04:59:43,441 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 05:01:16,771 - Epoch: [28][   10/   19]    Overall Loss 0.135763    Objective Loss 0.135763                                        LR 0.000500    Time 9.332980    
2025-10-29 05:01:52,132 - Epoch: [28][   19/   19]    Overall Loss 0.128187    Objective Loss 0.128187    Top1 94.169096    LR 0.000500    Time 6.770469    
2025-10-29 05:01:53,444 - --- validate (epoch=28)-----------
2025-10-29 05:01:53,445 - 521 samples (256 per mini-batch)
2025-10-29 05:02:35,452 - Epoch: [28][    3/    3]    Loss 0.124568    Top1 96.161228    
2025-10-29 05:02:36,783 - ==> Top1: 96.161    Loss: 0.125

2025-10-29 05:02:36,783 - ==> Confusion:
[[128   9]
 [ 11 373]]

2025-10-29 05:02:36,847 - ==> Best [Top1: 96.929   Params: 57776 on epoch: 25]
2025-10-29 05:02:36,848 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 05:02:36,855 - 

2025-10-29 05:02:36,855 - Training epoch: 4695 samples (256 per mini-batch, world size: 1)
2025-10-29 05:04:11,204 - Epoch: [29][   10/   19]    Overall Loss 0.108657    Objective Loss 0.108657                                        LR 0.000500    Time 9.434608    
2025-10-29 05:04:47,917 - Epoch: [29][   19/   19]    Overall Loss 0.114408    Objective Loss 0.114408    Top1 93.294461    LR 0.000500    Time 6.895327    
2025-10-29 05:04:49,257 - --- validate (epoch=29)-----------
2025-10-29 05:04:49,257 - 521 samples (256 per mini-batch)
2025-10-29 05:05:30,753 - Epoch: [29][    3/    3]    Loss 0.089241    Top1 95.969290    
2025-10-29 05:05:32,099 - ==> Top1: 95.969    Loss: 0.089

2025-10-29 05:05:32,099 - ==> Confusion:
[[128   9]
 [ 12 372]]

2025-10-29 05:05:32,163 - ==> Best [Top1: 96.929   Params: 57776 on epoch: 25]
2025-10-29 05:05:32,163 - Saving checkpoint to: logs\2025.10.29-033749\checkpoint.pth.tar
2025-10-29 05:05:32,170 - Initiating quantization aware training (QAT)...
2025-10-29 05:05:32,170 - Collecting statistics for quantization aware training (QAT)...
2025-10-29 05:07:36,050 - 
2025-10-29 05:07:36,051 - Log file for this run: D:\KRIZZ\COE187\ai8x-training\logs\2025.10.29-033749\2025.10.29-033749.log
